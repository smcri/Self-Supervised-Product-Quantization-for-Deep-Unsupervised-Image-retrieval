{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frDj8olJkPMB",
        "outputId": "453d0018-097f-4344-981f-a93d34c4cbbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kornia in /usr/local/lib/python3.7/dist-packages (0.6.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from kornia) (21.3)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from kornia) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.8.1->kornia) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->kornia) (3.0.8)\n"
          ]
        }
      ],
      "source": [
        " !pip install kornia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4w2Kh12qnzkx",
        "outputId": "ad5dc33e-3505-4cfc-f0a7-d2185fa6a630"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting Retrieval.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile Retrieval.py\n",
        "\n",
        "from utils import *\n",
        "from tqdm import tqdm\n",
        "\n",
        "def pqDist_one(C, N_books, g_x, q_x):\n",
        "    l1, l2 = C.shape\n",
        "    L_word = int(l2/N_books)\n",
        "    D_C = T.zeros((l1, N_books), dtype=T.float32)\n",
        "\n",
        "    q_x_split = T.split(q_x, L_word, 0)\n",
        "    g_x_split = np.split(g_x.cpu().data.numpy(), N_books, 1)\n",
        "    C_split = T.split(C, L_word, 1)\n",
        "    D_C_split = T.split(D_C, 1, 1)\n",
        "\n",
        "    for j in range(N_books):\n",
        "        for k in range(l1):\n",
        "            D_C_split[j][k] =T.norm(q_x_split[j]-C_split[j][k], 2)\n",
        "            #D_C_split[j][k] = T.norm(q_x_split[j]-C_split[j][k], 2).detach() #for PyTorch version over 1.9\n",
        "        if j == 0:\n",
        "            dist = D_C_split[j][g_x_split[j]]\n",
        "        else:\n",
        "            dist = T.add(dist, D_C_split[j][g_x_split[j]])\n",
        "    Dpq = T.squeeze(dist)\n",
        "    return Dpq\n",
        "\n",
        "def Indexing(C, N_books, X):              #stores minimum squared distance index of each subvector of X\n",
        "    l1, l2 = C.shape\n",
        "    L_word = int(l2/N_books)\n",
        "    x = T.split(X, L_word, 1)\n",
        "    y = T.split(C, L_word, 1)\n",
        "    for i in range(N_books):\n",
        "        diff = squared_distances(x[i], y[i])\n",
        "        arg = T.argmin(diff, dim=1)\n",
        "        min_idx = T.reshape(arg, [-1, 1])\n",
        "        if i == 0:\n",
        "            quant_idx = min_idx\n",
        "        else:\n",
        "            quant_idx = T.cat((quant_idx, min_idx), dim=1)\n",
        "    return quant_idx\n",
        "\n",
        "def Evaluate_mAP(C, N_books, gallery_codes, query_codes, gallery_labels, query_labels, device, TOP_K=None):\n",
        "    num_query = query_labels.shape[0]\n",
        "    mean_AP = 0.0\n",
        "\n",
        "    with T.no_grad():\n",
        "      with tqdm(total=num_query, desc=\"Evaluate mAP\", bar_format='{desc:<15}{percentage:3.0f}%|{bar:10}{r_bar}') as pbar:\n",
        "          for i in range(num_query):\n",
        "            # Retrieve images from database\n",
        "              retrieval = (query_labels[i, :] @ gallery_labels.t() > 0).float()\n",
        "\n",
        "            # Arrange position according to hamming distance\n",
        "              retrieval = retrieval[T.argsort(pqDist_one(C, N_books, gallery_codes, query_codes[i]))][:TOP_K]\n",
        "\n",
        "            # Retrieval count\n",
        "              retrieval_cnt = retrieval.sum().int().item()\n",
        "\n",
        "            # Can not retrieve images\n",
        "              if retrieval_cnt == 0:\n",
        "                  continue\n",
        "\n",
        "            # Generate score for every position\n",
        "              score = T.linspace(1, retrieval_cnt, retrieval_cnt).to(device)\n",
        "\n",
        "            # Acquire index\n",
        "              index = (T.nonzero(retrieval == 1, as_tuple=False).squeeze() + 1.0).float().to(device)\n",
        "\n",
        "              mean_AP += (score / index).mean()\n",
        "              pbar.update(1)\n",
        "\n",
        "          mean_AP = mean_AP / num_query\n",
        "    return mean_AP\n",
        "\n",
        "def DoRetrieval(device, args, net, C):\n",
        "    print(\"Do Retrieval!\")\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root=args.data_dir, train=True, download=args.if_download, transform=transforms.ToTensor())\n",
        "    Gallery_loader = T.utils.data.DataLoader(trainset, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)\n",
        "\n",
        "    testset = torchvision.datasets.CIFAR10(root=args.data_dir, train=False, download=args.if_download, transform=transforms.ToTensor())\n",
        "    Query_loader = T.utils.data.DataLoader(testset, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)\n",
        "\n",
        "    net.eval()\n",
        "    with T.no_grad():\n",
        "        with tqdm(total=len(Gallery_loader), desc=\"Build Gallery\", bar_format='{desc:<15}{percentage:3.0f}%|{bar:10}{r_bar}') as pbar:\n",
        "            for i, data in enumerate(Gallery_loader, 0):\n",
        "                gallery_x_batch, gallery_y_batch = data[0].to(device), data[1].to(device)\n",
        "                outputs = net(gallery_x_batch)\n",
        "                gallery_c_batch = Indexing(C, args.N_books, outputs[0])\n",
        "                gallery_y_batch = T.eye(args.num_cls)[gallery_y_batch]\n",
        "                if i == 0:\n",
        "                    gallery_c = gallery_c_batch\n",
        "                    gallery_y = gallery_y_batch\n",
        "                else:\n",
        "                    gallery_c = T.cat([gallery_c, gallery_c_batch], 0)\n",
        "                    gallery_y = T.cat([gallery_y, gallery_y_batch], 0)\n",
        "                pbar.update(1)\n",
        "\n",
        "        with tqdm(total=len(Query_loader), desc=\"Compute Query\", bar_format='{desc:<15}{percentage:3.0f}%|{bar:10}{r_bar}') as pbar:\n",
        "            for i, data in enumerate(Query_loader, 0):\n",
        "                query_x_batch, query_y_batch = data[0].to(device), data[1].to(device)\n",
        "                outputs = net(query_x_batch)\n",
        "                query_y_batch = T.eye(args.num_cls)[query_y_batch]\n",
        "                if i == 0:\n",
        "                    query_c = outputs[0]\n",
        "                    query_y = query_y_batch\n",
        "                else:\n",
        "                    query_c = T.cat([query_c, outputs[0]], 0)\n",
        "                    query_y = T.cat([query_y, query_y_batch], 0)\n",
        "                pbar.update(1)\n",
        "\n",
        "    mAP = Evaluate_mAP(C, args.N_books, gallery_c.type(T.int), query_c, gallery_y, query_y, device, args.Top_N)\n",
        "    return mAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWiUZiSsoGC5",
        "outputId": "c3d5bf30-8006-4c4e-90d3-812bd5291c9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting config.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile config.py\n",
        "\n",
        "#YouTube Faces (YTF), 1: FaceScrub (FS), 2: VGGFace2 (VGGF), 3: CASIA-WebFace (CW)\n",
        "\n",
        "cifar = dict(\n",
        "    NB_CLS=10,\n",
        "    input_size=224)\n",
        "\n",
        "cifar32 = dict(\n",
        "    Gallery_img_dir='./data/cifar',\n",
        "    Gallery_txt_dir='./data/cifar_Train.txt',\n",
        "    Query_img_dir='./data/cifar',\n",
        "    Query_txt_dir='./data/cifar_Query.txt',\n",
        "    NB_CLS=10,\n",
        "    input_size=32)\n",
        "\n",
        "ImageNet32 = dict(\n",
        "    Train_img_dir='./data/ImageNet_32',\n",
        "    Train_txt_dir='./data/ImageNet32.txt',\n",
        "    NB_CLS=1000,\n",
        "    input_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfAAiqkNogvh",
        "outputId": "30a036ca-d920-48cb-bf53-29e391375997"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting models.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile models.py\n",
        "\n",
        "import torch as T\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet_Baseline(nn.Module):\n",
        "    def __init__(self, block, num_blocks):\n",
        "        super(ResNet_Baseline, self).__init__()\n",
        "        self.in_planes = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.fc_out = nn.Linear(512*block.expansion, 512)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, out.size()[3])\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = F.relu(self.fc_out(out))\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDjgTQ6DopsB",
        "outputId": "c853fc9f-2e1f-46d0-a858-bae08bd669a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting utils.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile utils.py\n",
        "import os\n",
        "import argparse\n",
        "import torch as T\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torch.autograd import Variable\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import kornia.augmentation as Kg\n",
        "\n",
        "\n",
        "#define soft quatization function. This is the exponential of the squared euclidean distance between the \n",
        "#feature sub vector and the codeword(centroid), \n",
        "#divided by the sum of exponentials of squared distances over the other code words The closest codeword contributes the most to this quantised sum.\n",
        "\n",
        "def Soft_Quantization(X, C, N_books, tau_q):\n",
        "    L_word = int(C.size()[1]/N_books)  #calculate length of word as total code size/number of books\n",
        "    x = T.split(X, L_word, dim=1)      #split x into equal sized chunks\n",
        "    c = T.split(C, L_word, dim=1)      # split c into equalt sized chunks\n",
        "    for i in range(N_books):\n",
        "        soft_c = F.softmax(squared_distances(x[i], c[i]) * (-tau_q), dim=-1)  #calculate softmax\n",
        "        if i==0:\n",
        "            Z = soft_c @ c[i]   # @ operator is used for matrix multiplication, thus result of softmax is multiplied with codeword\n",
        "        else:\n",
        "            Z = T.cat((Z, soft_c @ c[i]), dim=1)   #concatenates the result to Z vector\n",
        "    return Z\n",
        "\n",
        "#returns sum of squared differences\n",
        "\n",
        "def squared_distances(x, y):\n",
        "    '''\n",
        "    Input: x is a Nxd matrix\n",
        "           y is an optional Mxd matirx\n",
        "    Output: dist is a NxM matrix where dist[i,j] is the square norm between x[i,:] and y[j,:]\n",
        "            if y is not given then use 'y=x'.\n",
        "    i.e. dist[i,j] = ||x[i,:]-y[j,:]||^2\n",
        "    '''\n",
        "    diff = x.unsqueeze(1) - y.unsqueeze(0) #unsqueeze is used to create a matrix of singleton list elments, the index is specified as argument.\n",
        "    return T.sum(diff * diff, -1)\n",
        "\n",
        "\n",
        "\n",
        "#create a Basic Building block neural network\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False) #convolutional neural network of kernal size 3x3 https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n",
        "        self.bn1 = nn.BatchNorm2d(planes)                                       #batch normalisation\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,                  #2nd convolutional layer\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)    #batch normalisation          \n",
        "\n",
        "        self.shortcut = nn.Sequential()  #used to add layers as they are passed to its constructor in a cascading matter(prev output is next input)\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))    #apply relu on all outputs and return, used for forward prop\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "#construct a baseline residual network\n",
        "\n",
        "class ResNet_Baseline(nn.Module):\n",
        "    def __init__(self, block, num_blocks):\n",
        "        super(ResNet_Baseline, self).__init__()\n",
        "        self.in_planes = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.fc_out = nn.Linear(512*block.expansion, 512)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, out.size()[3])\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = F.relu(self.fc_out(out))\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uh0FUaEoTSh",
        "outputId": "312d05fc-6a96-4cdf-da16-3d5bf911823e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting main_SPQ.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile main_SPQ.py\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from utils import *\n",
        "from Retrieval import *\n",
        "\n",
        "\n",
        "#argument parser\n",
        "def get_args_parser():\n",
        "    parser = argparse.ArgumentParser('SPQ', add_help=False)\n",
        "\n",
        "    parser.add_argument('--gpu_id', default=\"0\", type=str, help=\"\"\"Define GPU id.\"\"\")\n",
        "    parser.add_argument('--if_download', default=False, type=bool, help=\"\"\"Whether to download the dataset or not.\"\"\")\n",
        "    parser.add_argument('--data_dir', default=\"./data\", type=str, help=\"\"\"Path of the dataset to be installed.\"\"\")\n",
        "    parser.add_argument('--batch_size', default=256, type=int, help=\"\"\"Training mini-batch size.\"\"\")\n",
        "    parser.add_argument('--num_workers', default=12, type=int, help=\"\"\"Number of data loading workers per GPU.\"\"\")\n",
        "    parser.add_argument('--input_size', default=32, type=int, help=\"\"\"Input image size, default is set to CIFAR10.\"\"\")\n",
        "\n",
        "    parser.add_argument('--N_books', default=8, type=int, help=\"\"\"The number of the codebooks.\"\"\")\n",
        "    parser.add_argument('--N_words', default=16, type=int, help=\"\"\"The number of the codewords. It should be a power of two.\"\"\")\n",
        "    parser.add_argument('--L_word', default=16, type=int, help=\"\"\"Dimensionality of the codeword.\"\"\")\n",
        "    parser.add_argument('--soft_quantization_scale', default=5.0, type=float, help=\"\"\"Soft-quantization scaling parameter.\"\"\")\n",
        "    parser.add_argument('--contrastive_temperature', default=0.5, type=float, help=\"\"\"Contrastive learning Temperature scaling parameter.\"\"\")\n",
        "    \n",
        "    parser.add_argument('--num_cls', default=\"10\", type=int, help=\"\"\"The number of classes in the dataset for evaluation, default is set to CIFAR10\"\"\")\n",
        "    parser.add_argument('--eval_epoch', default=100, type=int, help=\"\"\"Compute mAP for Every N-th epoch.\"\"\")\n",
        "    parser.add_argument('--output_dir', default=\".\", type=str, help=\"\"\"Path to save logs and checkpoints.\"\"\")\n",
        "    parser.add_argument('--Top_N', default=1000, type=int, help=\"\"\"Top N number of images to be retrieved for evaluation.\"\"\")\n",
        "    \n",
        "    return parser\n",
        "\n",
        "\n",
        "class CQCLoss(T.nn.Module):\n",
        "\n",
        "    def __init__(self, device, batch_size, tau_cqc):\n",
        "        super(CQCLoss, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.tau_cqc = tau_cqc\n",
        "        self.device = device\n",
        "        self.COSSIM = T.nn.CosineSimilarity(dim=-1)\n",
        "        self.CE = T.nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "        self.get_corr_mask = self._get_correlated_mask().type(T.bool)\n",
        "\n",
        "    def _get_correlated_mask(self):\n",
        "        diag = np.eye(2 * self.batch_size)\n",
        "        l1 = np.eye((2 * self.batch_size), 2 * self.batch_size, k=-self.batch_size)\n",
        "        l2 = np.eye((2 * self.batch_size), 2 * self.batch_size, k=self.batch_size)\n",
        "        mask = T.from_numpy((diag + l1 + l2))\n",
        "        mask = (1 - mask).type(T.bool)\n",
        "        return mask.to(self.device)\n",
        "\n",
        "    def forward(self, Xa, Xb, Za, Zb):\n",
        "\n",
        "        XaZb = T.cat([Xa, Zb], dim=0)\n",
        "        XbZa = T.cat([Xb, Za], dim=0)\n",
        "\n",
        "        Cossim_ab = self.COSSIM(XaZb.unsqueeze(1), XaZb.unsqueeze(0))\n",
        "        Rab = T.diag(Cossim_ab, self.batch_size)\n",
        "        Lab = T.diag(Cossim_ab, -self.batch_size)\n",
        "        Pos_ab = T.cat([Rab, Lab]).view(2 * self.batch_size, 1)\n",
        "        Neg_ab = Cossim_ab[self.get_corr_mask].view(2 * self.batch_size, -1)\n",
        "\n",
        "        Cossim_ba = self.COSSIM(XbZa.unsqueeze(1), XbZa.unsqueeze(0))\n",
        "        Rba = T.diag(Cossim_ba, self.batch_size)\n",
        "        Lba = T.diag(Cossim_ba, -self.batch_size)    \n",
        "        Pos_ba = T.cat([Rba, Lba]).view(2 * self.batch_size, 1)\n",
        "        Neg_ba = Cossim_ba[self.get_corr_mask].view(2 * self.batch_size, -1)\n",
        "\n",
        "\n",
        "        logits_ab = T.cat((Pos_ab, Neg_ab), dim=1)\n",
        "        logits_ab /= self.tau_cqc\n",
        "\n",
        "        logits_ba = T.cat((Pos_ba, Neg_ba), dim=1)\n",
        "        logits_ba /= self.tau_cqc\n",
        "\n",
        "        labels = T.zeros(2 * self.batch_size).to(self.device).long()\n",
        "        \n",
        "        loss = self.CE(logits_ab, labels) + self.CE(logits_ba, labels)\n",
        "        return loss / (2 * self.batch_size)\n",
        "\n",
        "def train_SPQ(args):\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu_id\n",
        "    device = T.device('cuda')\n",
        "\n",
        "    sz = args.input_size\n",
        "    data_dir = args.data_dir\n",
        "    batch_size = args.batch_size\n",
        "\n",
        "    N_books = args.N_books\n",
        "    N_words = args.N_words\n",
        "    L_word = args.L_word\n",
        "    tau_q = args.soft_quantization_scale\n",
        "    tau_cqc = args.contrastive_temperature\n",
        "\n",
        "    N_bits = int(N_books * np.sqrt(N_words))\n",
        "    print('\\033[91m' + '%d'%N_bits +  '-bit to retrieval' + '\\033[0m')\n",
        "\n",
        "    #Define the data augmentation following the setup of SimCLR\n",
        "    Augmentation = nn.Sequential(\n",
        "        Kg.RandomResizedCrop(size=(sz, sz)),\n",
        "        Kg.RandomHorizontalFlip(p=0.5),\n",
        "        Kg.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1, p=0.8),\n",
        "        Kg.RandomGrayscale(p=0.2),\n",
        "        Kg.RandomGaussianBlur((int(0.1 * sz), int(0.1 * sz)), (0.1, 2.0), p=0.5))\n",
        "\n",
        "    transform = transforms.ToTensor()\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=args.if_download, transform=transform)\n",
        "    trainloader = T.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=args.num_workers)\n",
        "\n",
        "    class Quantization_Head(nn.Module):\n",
        "        def __init__(self, N_words, N_books, L_word, tau_q):\n",
        "            super(Quantization_Head, self).__init__()\n",
        "            self.fc = nn.Linear(512, N_books * L_word)\n",
        "            nn.init.xavier_uniform_(self.fc.weight)\n",
        "\n",
        "            # Codebooks\n",
        "            self.C = T.nn.Parameter(Variable((T.randn(N_words, N_books * L_word)).type(T.float32), requires_grad=True))\n",
        "            nn.init.xavier_uniform_(self.C)\n",
        "\n",
        "            self.N_books = N_books\n",
        "            self.L_word = L_word\n",
        "            self.tau_q = tau_q\n",
        "\n",
        "        def forward(self, input):\n",
        "            X = self.fc(input)\n",
        "            Z = Soft_Quantization(X, self.C, self.N_books, self.tau_q)\n",
        "            return X, Z\n",
        "        \n",
        "    Q = Quantization_Head(N_words, N_books, L_word, tau_q)\n",
        "    net = nn.Sequential(ResNet_Baseline(BasicBlock, [2, 2, 2, 2]), Q)\n",
        "\n",
        "    net.cuda(device)\n",
        "    checkpoint = T.load('32_0.7247_checkpoint.pth')\n",
        "    \n",
        "    criterion = CQCLoss(device, batch_size, tau_cqc)\n",
        "\n",
        "    optimizer = T.optim.Adam(net.parameters(), lr=3e-4, weight_decay=10e-6)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=len(trainloader), eta_min=0, last_epoch=-1)\n",
        "\n",
        "    net.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "    MAX_mAP = 0.0\n",
        "    mAP = 0.0\n",
        "\n",
        "    for epoch in range(5000):  # loop over the dataset multiple times\n",
        "\n",
        "        print('Epoch: %d, Learning rate: %.4f' % (epoch, scheduler.get_last_lr()[0]))\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs = data[0].to(device)\n",
        "            Ilist = list()\n",
        "            Xlist = list()\n",
        "            Zlist = list()\n",
        "\n",
        "            n = 5\n",
        "\n",
        "            for k in range(n):\n",
        "              Ilist.append(Augmentation(inputs))\n",
        "           # Ia = Augmentation(inputs)\n",
        "           # Ib = Augmentation(inputs)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            #Xa, Za = net(Ia)\n",
        "            #Xb, Zb = net(Ib)\n",
        "\n",
        "            for k in range(n):\n",
        "              Xa, Za = net(Ilist[k])\n",
        "              Xlist.append(Xa)\n",
        "              Zlist.append(Za)\n",
        "            \n",
        "            loss = 0\n",
        "\n",
        "            for k in range(n):\n",
        "              for l in range(n):\n",
        "                if not (k == l):\n",
        "                  loss = loss + criterion(Xlist[k], Xlist[l], Zlist[k], Zlist[l])\n",
        "                  \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            #loss = criterion(Xa, Xb, Za, Zb)\n",
        "            #loss.backward()\n",
        "            #optimizer.step()\n",
        "\n",
        "            #running_loss += loss.item()\n",
        "\n",
        "            if (i+1) % 10 == 0:    # print every 10 mini-batches\n",
        "                print('[%3d] loss: %.4f, mAP: %.4f, MAX mAP: %.4f' %\n",
        "                    (i+1, running_loss / (10*n), mAP, MAX_mAP))\n",
        "                \n",
        "                store_loss = running_loss / (10*n)\n",
        "                running_loss = 0.0\n",
        "\n",
        "        if epoch >= 10:\n",
        "            scheduler.step()\n",
        "        \n",
        "        if (epoch+1) % args.eval_epoch == 0:\n",
        "            mAP = DoRetrieval(device, args, net, Q.C)\n",
        "            if mAP > MAX_mAP:\n",
        "                Result_path = os.path.join(args.output_dir, \"%d_%.4f_checkpoint.pth\"%(N_bits, mAP))\n",
        "                T.save({\n",
        "                  'epoch': epoch,\n",
        "                  'model_state_dict': net.state_dict(),\n",
        "                  'optimizer_state_dict': optimizer.state_dict(),\n",
        "                  'loss': store_loss,\n",
        "                  }, Result_path)\n",
        "                #T.save(net.state_dict(), Result_path)\n",
        "                MAX_mAP = mAP\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser('SPQ', parents=[get_args_parser()])\n",
        "    args = parser.parse_args()\n",
        "    train_SPQ(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3N-cP7Hpo0Ky",
        "outputId": "6935c3aa-87ad-4ae1-8d88-72b54ac20a6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[91m32-bit to retrieval\u001b[0m\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: 0, Learning rate: 0.0003\n",
            "[ 10] loss: 38.3867, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 20] loss: 38.1224, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 30] loss: 37.8955, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 40] loss: 37.7422, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 50] loss: 37.7395, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 60] loss: 37.6646, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 70] loss: 37.6509, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 80] loss: 37.6385, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 90] loss: 37.6104, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[100] loss: 37.5648, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[110] loss: 37.5526, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[120] loss: 37.5766, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[130] loss: 37.5397, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[140] loss: 37.5865, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[150] loss: 37.5886, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[160] loss: 37.5284, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[170] loss: 37.6345, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[180] loss: 37.5035, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[190] loss: 37.5912, mAP: 0.0000, MAX mAP: 0.0000\n",
            "Epoch: 1, Learning rate: 0.0003\n",
            "[ 10] loss: 37.5511, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 20] loss: 37.4172, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 30] loss: 37.4873, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 40] loss: 37.5366, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 50] loss: 37.4454, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 60] loss: 37.4572, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 70] loss: 37.5913, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 80] loss: 37.4896, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 90] loss: 37.4748, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[100] loss: 37.4731, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[110] loss: 37.4697, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[120] loss: 37.5353, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[130] loss: 37.5030, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[140] loss: 37.4222, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[150] loss: 37.5250, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[160] loss: 37.4643, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[170] loss: 37.5300, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[180] loss: 37.5048, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[190] loss: 37.4436, mAP: 0.0000, MAX mAP: 0.0000\n",
            "Epoch: 2, Learning rate: 0.0003\n",
            "[ 10] loss: 37.3854, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 20] loss: 37.4378, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 30] loss: 37.4486, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 40] loss: 37.5181, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 50] loss: 37.4904, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 60] loss: 37.3838, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 70] loss: 37.3659, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 80] loss: 37.4539, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 90] loss: 37.4186, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[100] loss: 37.4185, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[110] loss: 37.4564, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[120] loss: 37.4030, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[130] loss: 37.4032, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[140] loss: 37.4173, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[150] loss: 37.3710, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[160] loss: 37.4781, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[170] loss: 37.4519, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[180] loss: 37.3713, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[190] loss: 37.4137, mAP: 0.0000, MAX mAP: 0.0000\n",
            "Epoch: 3, Learning rate: 0.0003\n",
            "[ 10] loss: 37.3738, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 20] loss: 37.3686, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 30] loss: 37.3441, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 40] loss: 37.3956, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 50] loss: 37.3810, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 60] loss: 37.4662, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 70] loss: 37.4008, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 80] loss: 37.4465, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 90] loss: 37.4123, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[100] loss: 37.4264, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[110] loss: 37.3680, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[120] loss: 37.3242, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[130] loss: 37.3471, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[140] loss: 37.5103, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[150] loss: 37.3084, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[160] loss: 37.3848, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[170] loss: 37.4068, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[180] loss: 37.3675, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[190] loss: 37.3630, mAP: 0.0000, MAX mAP: 0.0000\n",
            "Epoch: 4, Learning rate: 0.0003\n",
            "[ 10] loss: 37.4291, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 20] loss: 37.3837, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 30] loss: 37.3541, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 40] loss: 37.4050, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 50] loss: 37.3507, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 60] loss: 37.3160, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 70] loss: 37.3843, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 80] loss: 37.3815, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[ 90] loss: 37.4395, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[100] loss: 37.3231, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[110] loss: 37.3744, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[120] loss: 37.4197, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[130] loss: 37.3699, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[140] loss: 37.3690, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[150] loss: 37.3321, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[160] loss: 37.4538, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[170] loss: 37.3993, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[180] loss: 37.4286, mAP: 0.0000, MAX mAP: 0.0000\n",
            "[190] loss: 37.3263, mAP: 0.0000, MAX mAP: 0.0000\n",
            "Do Retrieval!\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Build Gallery: 100% 196/196 [00:43<00:00,  4.51it/s]\n",
            "Compute Query: 100% 40/40 [00:09<00:00,  4.22it/s]\n",
            "Evaluate mAP: 100% 9995/10000 [04:05<00:00, 40.75it/s]\n",
            "Epoch: 5, Learning rate: 0.0003\n",
            "[ 10] loss: 37.4939, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 20] loss: 37.6938, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 30] loss: 37.6351, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 40] loss: 37.6437, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 50] loss: 37.5765, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 60] loss: 37.3928, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 70] loss: 37.3576, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 80] loss: 37.3993, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 90] loss: 37.3554, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[100] loss: 37.3268, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[110] loss: 37.3884, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[120] loss: 37.3051, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[130] loss: 37.2177, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[140] loss: 37.3604, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[150] loss: 37.4034, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[160] loss: 37.3828, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[170] loss: 37.2431, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[180] loss: 37.2340, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[190] loss: 37.3358, mAP: 0.7003, MAX mAP: 0.7003\n",
            "Epoch: 6, Learning rate: 0.0003\n",
            "[ 10] loss: 37.2946, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 20] loss: 37.2662, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 30] loss: 37.2247, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 40] loss: 37.2783, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 50] loss: 37.2073, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 60] loss: 37.3506, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 70] loss: 37.3538, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 80] loss: 37.2967, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 90] loss: 37.2158, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[100] loss: 37.2688, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[110] loss: 37.1967, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[120] loss: 37.2680, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[130] loss: 37.2227, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[140] loss: 37.2629, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[150] loss: 37.2363, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[160] loss: 37.2623, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[170] loss: 37.2341, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[180] loss: 37.2013, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[190] loss: 37.2327, mAP: 0.7003, MAX mAP: 0.7003\n",
            "Epoch: 7, Learning rate: 0.0003\n",
            "[ 10] loss: 37.2725, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 20] loss: 37.1753, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 30] loss: 37.2155, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 40] loss: 37.1283, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 50] loss: 37.1357, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 60] loss: 37.0957, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 70] loss: 37.0653, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 80] loss: 37.1695, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 90] loss: 37.1690, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[100] loss: 37.2141, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[110] loss: 37.1353, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[120] loss: 37.1621, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[130] loss: 37.1137, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[140] loss: 37.1290, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[150] loss: 37.1377, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[160] loss: 37.2006, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[170] loss: 37.2556, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[180] loss: 37.1267, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[190] loss: 37.1130, mAP: 0.7003, MAX mAP: 0.7003\n",
            "Epoch: 8, Learning rate: 0.0003\n",
            "[ 10] loss: 37.0771, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 20] loss: 37.1320, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 30] loss: 37.1572, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 40] loss: 37.1760, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 50] loss: 37.1116, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 60] loss: 37.0787, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 70] loss: 37.1986, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 80] loss: 37.2372, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 90] loss: 37.1702, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[100] loss: 37.1903, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[110] loss: 37.1222, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[120] loss: 37.0865, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[130] loss: 37.1167, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[140] loss: 37.1206, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[150] loss: 37.1475, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[160] loss: 37.0745, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[170] loss: 37.1549, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[180] loss: 37.1337, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[190] loss: 37.1185, mAP: 0.7003, MAX mAP: 0.7003\n",
            "Epoch: 9, Learning rate: 0.0003\n",
            "[ 10] loss: 37.0287, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 20] loss: 37.1243, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 30] loss: 37.1282, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 40] loss: 37.1392, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 50] loss: 37.1648, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 60] loss: 37.1326, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 70] loss: 37.0931, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 80] loss: 37.2328, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[ 90] loss: 37.1610, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[100] loss: 37.0237, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[110] loss: 37.0767, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[120] loss: 37.0314, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[130] loss: 37.0960, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[140] loss: 37.1518, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[150] loss: 37.0868, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[160] loss: 37.1423, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[170] loss: 37.1411, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[180] loss: 37.1161, mAP: 0.7003, MAX mAP: 0.7003\n",
            "[190] loss: 37.1059, mAP: 0.7003, MAX mAP: 0.7003\n",
            "Do Retrieval!\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Build Gallery: 100% 196/196 [00:43<00:00,  4.53it/s]\n",
            "Compute Query: 100% 40/40 [00:09<00:00,  4.24it/s]\n",
            "Evaluate mAP: 100% 9996/10000 [04:03<00:00, 41.02it/s]\n",
            "Epoch: 10, Learning rate: 0.0003\n",
            "[ 10] loss: 37.0181, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 20] loss: 37.0897, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 30] loss: 37.1288, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 40] loss: 37.1794, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 50] loss: 37.1276, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 60] loss: 37.1080, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 70] loss: 37.0474, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 80] loss: 37.0804, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 90] loss: 37.0287, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[100] loss: 37.1431, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[110] loss: 37.0843, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[120] loss: 37.0647, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[130] loss: 37.0742, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[140] loss: 37.0705, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[150] loss: 37.1021, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[160] loss: 37.0863, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[170] loss: 37.1353, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[180] loss: 37.1191, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[190] loss: 37.0488, mAP: 0.7298, MAX mAP: 0.7298\n",
            "Epoch: 11, Learning rate: 0.0003\n",
            "[ 10] loss: 37.1019, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 20] loss: 37.0994, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 30] loss: 37.1012, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 40] loss: 37.1082, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 50] loss: 37.1239, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 60] loss: 37.1292, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 70] loss: 37.0185, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 80] loss: 37.1518, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 90] loss: 37.1906, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[100] loss: 37.0422, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[110] loss: 37.0625, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[120] loss: 37.0105, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[130] loss: 37.0271, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[140] loss: 37.1028, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[150] loss: 37.0512, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[160] loss: 37.0911, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[170] loss: 37.0765, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[180] loss: 37.1418, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[190] loss: 37.0779, mAP: 0.7298, MAX mAP: 0.7298\n",
            "Epoch: 12, Learning rate: 0.0003\n",
            "[ 10] loss: 36.9945, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 20] loss: 37.0286, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 30] loss: 37.1347, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 40] loss: 36.9278, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 50] loss: 37.0040, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 60] loss: 37.0608, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 70] loss: 37.0009, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 80] loss: 37.0993, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 90] loss: 37.1058, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[100] loss: 37.0506, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[110] loss: 37.1372, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[120] loss: 37.0972, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[130] loss: 37.1055, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[140] loss: 36.9985, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[150] loss: 37.1212, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[160] loss: 37.0753, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[170] loss: 37.0206, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[180] loss: 37.0207, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[190] loss: 37.0346, mAP: 0.7298, MAX mAP: 0.7298\n",
            "Epoch: 13, Learning rate: 0.0003\n",
            "[ 10] loss: 37.0629, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 20] loss: 37.1240, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 30] loss: 36.9783, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 40] loss: 37.1020, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 50] loss: 37.0396, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 60] loss: 37.1074, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 70] loss: 37.0870, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 80] loss: 37.0744, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 90] loss: 36.9901, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[100] loss: 37.0879, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[110] loss: 37.0804, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[120] loss: 37.0320, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[130] loss: 37.0893, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[140] loss: 37.0131, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[150] loss: 37.0700, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[160] loss: 37.1038, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[170] loss: 37.0867, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[180] loss: 37.0201, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[190] loss: 37.1133, mAP: 0.7298, MAX mAP: 0.7298\n",
            "Epoch: 14, Learning rate: 0.0003\n",
            "[ 10] loss: 37.0749, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 20] loss: 37.1030, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 30] loss: 37.0306, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 40] loss: 37.0145, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 50] loss: 37.1280, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 60] loss: 37.0201, mAP: 0.7298, MAX mAP: 0.7298\n",
            "[ 70] loss: 37.0162, mAP: 0.7298, MAX mAP: 0.7298\n"
          ]
        }
      ],
      "source": [
        "!python main_SPQ.py --gpu_id=0 --batch_size=256 --N_books=8 --N_words=16 --eval_epoch=5 --if_download=True"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "VRN_project.pynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}